{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56712cc3",
   "metadata": {},
   "source": [
    "## Part 1: Document Loading\n",
    "\n",
    "Type of documents covered:\n",
    "- PDFs\n",
    "- Youtube Videos\n",
    "- Website \n",
    "\n",
    "Import and stardardise such that we obtain:\n",
    "- Content\n",
    "- Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0903c131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Connecting to account\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/openai_api_key.env\")) # read local .env file\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be432a",
   "metadata": {},
   "source": [
    "### PDF\n",
    "\n",
    "Each page is a Document. A Document contains text (page_content) and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266bd93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install pypdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ca6c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/Langchain for LLM applications/Deep_Learning_A4.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a330a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page = pages[0]\n",
    "page.page_content[0:500] # number of characters\n",
    "page.metadata # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21741b7c",
   "metadata": {},
   "source": [
    "### Youtube (Broken - to be fixed)\n",
    "- Issue: yt_dlp can't find the ffmpeg files, even though they're properly installed on the local device. Didn't resolve why yet...\n",
    "- Tutorial used: https://www.youtube.com/watch?v=IECI72XEox0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e259a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install yt_dlp\n",
    "# ! pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952ae3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser # converts youtube audio to text format (langchain model)\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340b772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Youtube URL (video: Josh Angrist: What's the Difference Between Econometrics and Data Science? - 2 min)\n",
    "url = \"https://www.youtube.com/watch?v=2EhRT2mOXm8&t=2s\"\n",
    "\n",
    "# Directory where to save audio\n",
    "save_dir = \"C:/Users/richi/OneDrive/Documents/OpenAI API practice/Langchain for LLM applications/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41458f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DOESN'T WORK FOR SOME REASON - installed fmpeg stuff...\n",
    "\n",
    "# Note: may take a while & will give error if the content is already present/downloaded in file directory\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bab88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = docs[0]\n",
    "doc.page_content[0: 500]\n",
    "doc.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a3065",
   "metadata": {},
   "source": [
    "### URLs\n",
    "\n",
    "Note: format is probably really poorly formatted, so we should post-process for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ddbe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://richie-lee.github.io/post/2021_uplift/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf466807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90bb22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = docs[0]\n",
    "doc.page_content[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df53ca",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Document splitting\n",
    "\n",
    "*After* loading data and *before* feeding it into the vector store \n",
    "\n",
    "Fundamental concept: splitting on chunks with some size, with overlap. This overlap is helpful in ensuring no information is loss when splitting texts.\n",
    "\n",
    "Types of splitting:\n",
    "- **CharacterTextSplitter():** based on characters\n",
    "- **MarkdownHeaderTextSplitter():** based on MD headers\n",
    "- **TokenTextSplitter():** based on tokens\n",
    "- **RecursiveCharacterTextSplitter():** recursively tries to split by different characters to see what works\n",
    "- **Language():** for Python, Ruby, Markdown, ...\n",
    "- **NLTKTextSplitter():** based on sentences and NLTK (natural language tool kit)\n",
    "- **SpacyTextSplitter():** based on sentences and Spacy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56f0b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Connecting to account\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/openai_api_key.env\")) # read local .env file\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11bd48",
   "metadata": {},
   "source": [
    "Intuitive examples of (Recursive) character text splitters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c288628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04e59b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abb5b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialise two different text splitters\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909bc0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n < 26 (chunk size)\n",
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "print(r_splitter.split_text(text1))\n",
    "\n",
    "# n > 26 (chunk size)\n",
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "print(r_splitter.split_text(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18841dcb",
   "metadata": {},
   "source": [
    "character text splitting issue: it splits on a new characters, by default a newline char, but here there arent't any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b37cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "print(r_splitter.split_text(text3)) # recursive character text splitting\n",
    "print(c_splitter.split_text(text3)) # character text splitting: issue it splits on a new characters, by default a newline char, but here there arent't any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2133d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note - given processing C & R become equivalent\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb6f82",
   "metadata": {},
   "source": [
    "Recursive splitting details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00937937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b430512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09182815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] # default sepearators, but here for illustration explicitly displayed - it moves from left to right recursively\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f45022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only splits on spaces\n",
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47821590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splits on \\n\\n first, and then rest respectively for better quality due to importance hierarchy\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d203fa",
   "metadata": {},
   "source": [
    "For periods, define regex with lookback for better results: \"(?<=\\.)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d355068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"] # separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"] not this due to REGEX under the hood\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2868ede2",
   "metadata": {},
   "source": [
    "Try with real example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52eb823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/Langchain for LLM applications/Deep_Learning_A4.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da2f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda3b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f8fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To illustrate difference it may make\n",
    "print(len(docs), len(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956571f2",
   "metadata": {},
   "source": [
    "**Token splitting:** LLMs often have context windows designated in tokens (approx 4 characters often)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3684a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b0735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333ddd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text1 = \"foo bar bazzyfoo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2494a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7819d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86787c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a21ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note metadata is same in chunk as in pages (which is good).\n",
    "docs[0]\n",
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fadeeb7",
   "metadata": {},
   "source": [
    "**Context aware splitting:** adds meta data to the text chunks\n",
    "\n",
    "- chunks aim to keep text with common context together\n",
    "- text splitting often uses sentences or other delimiters to keep related text together, but some docs have explicit structures that can be used (e.g. markdown headers) - headers become metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d91e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9cc21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bcab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5227313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f2dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(md_header_splits)) # number chunks\n",
    "\n",
    "print(md_header_splits[0]) # first chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0761b0",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Vectorstores & Embeddings\n",
    "Retrieval augmented generation workflow:\n",
    "\n",
    "Documents => smaller splits => embedding => store in vectorstore \n",
    "\n",
    "- Embedding: numerical representation of text (similar embeddings = similar texts)\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e8a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Connecting to account\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/openai_api_key.env\")) # read local .env file\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dbfa0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/Langchain chat with your data/DL_A4.pdf\"),\n",
    "    PyPDFLoader(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/Langchain chat with your data/DL_A4.pdf\"),\n",
    "    PyPDFLoader(\"C:/Users/richi/OneDrive/Documents/OpenAI API practice/Langchain chat with your data/DL_A5.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da8f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b3080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8706aa5",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "Simple example to understand what's happening under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce739e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892114e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006d6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to vectors/embeddings\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8985c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test similarity of embeddings\n",
    "import numpy as np\n",
    "print(f\"[1, 2]: {np.dot(embedding1, embedding2)}\")\n",
    "print(f\"[1, 3]: {np.dot(embedding1, embedding3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7dbc55",
   "metadata": {},
   "source": [
    "### Vectorstores\n",
    "\n",
    "- Vectorstore used: Chroma (lightweight & in-memory)\n",
    "- Other vector stores can be hosted, which would be better for larger scale projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8672e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Installation not necessarily straight-forward: \n",
    "# - Go to https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "# - Download & make sure to toggle C++\n",
    "\n",
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a782bbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b61c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save at directory (for future usage) - check if there's not something already there, as it may fuck shit up\n",
    "persist_directory = 'C:/Users/richi/OneDrive/Documents/OpenAI API practice/Langchain chat with your data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6389ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory = persist_directory # chroma-specific keyword\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d357ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: same as number of splits as before\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc3223",
   "metadata": {},
   "source": [
    "**Similarity search**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b8742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"What's the advantage of a recurrent neural network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780a498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3) # k = number of documents we want to return\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46c21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looks at (embeddings of) chunks and sees which one matches the best \n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02186f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save to use later\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138ea65",
   "metadata": {},
   "source": [
    "### Failure Modes\n",
    "Edge cases that we should be aware of that cause problems with standard implementations\n",
    "- Duplicates (for duplicate input)\n",
    "- Sub-optimal chunks by not leveraging structured information over regular semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566d22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs = vectordb.similarity_search(question, k = 5)\n",
    "\n",
    "# Produces duplicates (due to duplicate input data) - no additional value, distint chunks would be more valuable\n",
    "print(docs[0], \"\\n\\n\", docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb73f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about reinforcement?\"\n",
    "docs = vectordb.similarity_search(question,k=5)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)\n",
    "\n",
    "# It doesn't capture/prioritise structured information over normal sentence semantics and may therefore not prioritise the most relevant info\n",
    "print(docs[4].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
